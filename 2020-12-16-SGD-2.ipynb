{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-12-16-SGD-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfatou7DHRzsPlWJWcAIQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsqihui/ai/blob/master/2020-12-16-SGD-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz7zuSy1Skpc"
      },
      "source": [
        "# SGD 实验2\r\n",
        "> SGD的应用以及pytorch的基本使用 (基于fast.ai lesson 4)\r\n",
        "\r\n",
        "- toc:true\r\n",
        "- branch: master\r\n",
        "- badges: true\r\n",
        "- comments: true\r\n",
        "- author: jsqihui\r\n",
        "- categories: [fast.ai]\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBpqe_FH6Zof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d67a294-4a2f-4bcd-8526-09332bbf4c20"
      },
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 727kB 5.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 30.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 42.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25KLUjzvhPXx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c70d14f3-6603-4371-c71b-86b5a193ef31"
      },
      "source": [
        "#hide\r\n",
        "path = untar_data(URLs.MNIST_SAMPLE)\r\n",
        "Path.BASE_PATH = path\r\n",
        "threes = (path/'train'/'3').ls().sorted()\r\n",
        "sevens = (path/'train'/'7').ls().sorted()\r\n",
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\r\n",
        "three_tensors = [tensor(Image.open(o)) for o in threes]\r\n",
        "stacked_sevens = torch.stack(seven_tensors).float()/255\r\n",
        "stacked_threes = torch.stack(three_tensors).float()/255\r\n",
        "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])\r\n",
        "valid_3_tens = valid_3_tens.float()/255\r\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()])\r\n",
        "valid_7_tens = valid_7_tens.float()/255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z5jOiSRAiRO"
      },
      "source": [
        "#hide\r\n",
        "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\r\n",
        "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\r\n",
        "dset = list(zip(train_x,train_y))\r\n",
        "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\r\n",
        "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\r\n",
        "valid_dset = list(zip(valid_x,valid_y))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIuJZecKCADQ",
        "outputId": "34b709fc-9b4f-4101-f6ee-201efe62a8fd"
      },
      "source": [
        "x, y = dset[0]\r\n",
        "x.shape, y.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), torch.Size([1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs8esFltDHzX"
      },
      "source": [
        "这里把每一幅图28*28pixel变成一个vector，也就是[1x784]的一个tensor。label变成[1x1]的tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRXB-ZzVDqPW"
      },
      "source": [
        "利用的architecture是 (Weight*ImageTensor).sum()+bias。\r\n",
        "> Tip: 这里的weight和ImageTensor是bitwise multiply，也就是每一个pixel有一个weight，得出来的tensor还是[1x784]的大小"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEu55FRehPY2"
      },
      "source": [
        "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\r\n",
        "weights = init_params((28*28,1))\r\n",
        "bias = init_params(1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpYpGnSrDGVi",
        "outputId": "93ef3ecf-0557-4ebc-df24-c7efe4072285"
      },
      "source": [
        "(train_x[0]*weights.T).sum() + bias"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([15.7077], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH_9Rf02Fybl"
      },
      "source": [
        "利用pytorch的GPU功能来计算\"@\"表示是矩阵乘法"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7m94ajsFc3B"
      },
      "source": [
        "def linear1(xb): return xb@weights + bias\r\n",
        "preds = linear1(train_x)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKrxL8-8GxjA"
      },
      "source": [
        "其实这里preds>0.0就是loss function，这里的0是随意选取的，没有太大意义。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7nkKkMNFlAI",
        "outputId": "8463ede3-08c0-4a67-ea11-bc42ece2963d"
      },
      "source": [
        "corrects = (preds>0.0).float() == train_y\r\n",
        "corrects.float().mean().item()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5525975823402405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcYPZSSnHhg-",
        "outputId": "e67bde17-150e-489f-c17c-d0db8f24081e"
      },
      "source": [
        "weights[0] *= 1.0001\r\n",
        "preds = linear1(train_x)\r\n",
        "((preds>0.0).float() == train_y).float().mean().item()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5525975823402405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd7n0jV8HvyO"
      },
      "source": [
        "从[SGD实验1](https://jsqihui.github.io/ai/fast.ai/2020/12/16/SGD-1.html)里，我们知道我们的最终目的是得出合适的parameter，这里也就是weights和bias，来带入architecture做预测。要得出合适的parameter，就是要通过计算parameter的gradient,然后通过 parameter = parameter - (learning rate) * gradient来更新parameter。而gradient是通过loss function的derivative来求得的。但是有的loss function当parameter是0的时候，它的derivative也是0，比如说 loss = x^2。这样的话parameter就不会被更新。我们希望找到一种loss function，使得只要跟新一点点weight使得prediction变好一点，它的loss也会变小一点。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKa4zWp3L88I"
      },
      "source": [
        "Having defined a loss function, now is a good moment to recapitulate why we did this. After all, we already had a metric, which was overall accuracy. So why did we define a loss?\r\n",
        "\r\n",
        "The key difference is that the metric is to drive human understanding and the loss is to drive automated learning. To drive automated learning, the loss must be a function that has a meaningful derivative. It can't have big flat sections and large jumps, but instead must be reasonably smooth. This is why we designed a loss function that would respond to small changes in confidence level. This requirement means that sometimes it does not really reflect exactly what we are trying to achieve, but is rather a compromise between our real goal, and a function that can be optimized using its gradient. The loss function is calculated for each item in our dataset, and then at the end of an epoch the loss values are all averaged and the overall mean is reported for the epoch.\r\n",
        "\r\n",
        "Metrics, on the other hand, are the numbers that we really care about. These are the values that are printed at the end of each epoch that tell us how our model is really doing. It is important that we learn to focus on these metrics, rather than the loss, when judging the performance of a model.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ3-pSueMVBX"
      },
      "source": [
        "下面这个loss function就符合要求，先把所有的prediction用sigmoid变到[0,1]内，然后直接计算距离的mean值。上面这段是直接从fast.ai的书里摘录出来的，对理解metric和loss function的区别很有帮助。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYB7ETYPcQIz"
      },
      "source": [
        "weights = init_params((28*28,1))\r\n",
        "bias = init_params(1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPfPBdtKhPZD"
      },
      "source": [
        "def mnist_loss(predictions, targets):\n",
        "    predictions = predictions.sigmoid() # torch的function\n",
        "    return torch.where(targets==1, 1-predictions, predictions).mean()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_G-8ud7LM8l"
      },
      "source": [
        "dl = DataLoader(dset, batch_size=256)\r\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5MCZb_JcnVg"
      },
      "source": [
        "把所有的合并成一个function，计算preds，然后计算loss，然后通过loss计算gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj3akEFVNUDg"
      },
      "source": [
        "def calc_grad(xb, yb, model):\r\n",
        "    preds = model(xb)\r\n",
        "    loss = mnist_loss(preds, yb)\r\n",
        "    loss.backward()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KurB2KUWcwmN"
      },
      "source": [
        "当calc_grad计算出gradient后，更新parameter。并重置gradient\r\n",
        "> Warning: 为何要重置gradient？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUtY3vcBOMp9"
      },
      "source": [
        "def train_epoch(model, lr, params):\r\n",
        "    for xb,yb in dl:\r\n",
        "        calc_grad(xb, yb, model)\r\n",
        "        for p in params:\r\n",
        "            p.data -= p.grad*lr\r\n",
        "            p.grad.zero_()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYO4gzNYhPZO"
      },
      "source": [
        "def batch_accuracy(xb, yb):\n",
        "    preds = xb.sigmoid()\n",
        "    correct = (preds>0.5) == yb\n",
        "    return correct.float().mean()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tghT2hdZhPZP"
      },
      "source": [
        "def validate_epoch(model):\n",
        "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
        "    return round(torch.stack(accs).mean().item(), 4)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwFvZK2RSJGY",
        "outputId": "fe2c630f-fda4-4877-cc3a-f1f1e826d4a2"
      },
      "source": [
        "lr = 1.\r\n",
        "params = weights,bias\r\n",
        "train_epoch(linear1, lr, params)\r\n",
        "validate_epoch(linear1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.707"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izeECQx4SLq_",
        "outputId": "ef979c77-8da8-4414-9104-8f4b622f505f"
      },
      "source": [
        "for i in range(20):\r\n",
        "    train_epoch(linear1, lr, params)\r\n",
        "    print(validate_epoch(linear1), end=' ')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8539 0.9081 0.9291 0.9365 0.9443 0.9482 0.954 0.9589 0.9609 0.9623 0.9633 0.9662 0.9667 0.9682 0.9682 0.9687 0.9687 0.9692 0.9702 0.9702 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzMwlSRfeIFZ"
      },
      "source": [
        "# pytorch提供了很多有用的function，免去了自己去创造"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_TBs1vHeR-c"
      },
      "source": [
        "linear_model = nn.Linear(28*28,1)\r\n",
        "class BasicOptim:\r\n",
        "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\r\n",
        "\r\n",
        "    def step(self, *args, **kwargs):\r\n",
        "        for p in self.params: p.data -= p.grad.data * self.lr\r\n",
        "\r\n",
        "    def zero_grad(self, *args, **kwargs):\r\n",
        "        for p in self.params: p.grad = None\r\n",
        "opt = BasicOptim(linear_model.parameters(), lr)\r\n",
        "def train_epoch(model):\r\n",
        "    for xb,yb in dl:\r\n",
        "        calc_grad(xb, yb, model)\r\n",
        "        opt.step()\r\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3ie2ABBeoWz"
      },
      "source": [
        "def train_model(model, epochs):\r\n",
        "    for i in range(epochs):\r\n",
        "        train_epoch(model)\r\n",
        "        print(validate_epoch(model), end=' ')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61Ec7StTeveY",
        "outputId": "d1ad8618-1f4f-4a39-ee0a-bb5e14f96566"
      },
      "source": [
        "train_model(linear_model, 20)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4932 0.8335 0.8438 0.9116 0.9341 0.9482 0.9565 0.9624 0.9658 0.9678 0.9692 0.9717 0.9736 0.9746 0.9761 0.9761 0.9775 0.978 0.9785 0.979 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E42yVzkIe1D1"
      },
      "source": [
        "fastbook也提供了一些wrapper，比如说SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nTZfZBje4op"
      },
      "source": [
        "dls = DataLoaders(dl, valid_dl)\r\n",
        "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\r\n",
        "                loss_func=mnist_loss, metrics=batch_accuracy)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "jAjrHpDOfERl",
        "outputId": "f66a0076-719c-491c-bc81-3f7f42796913"
      },
      "source": [
        "learn.fit(10, lr=lr)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.637081</td>\n",
              "      <td>0.503588</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.566746</td>\n",
              "      <td>0.186157</td>\n",
              "      <td>0.844946</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.206826</td>\n",
              "      <td>0.185936</td>\n",
              "      <td>0.832188</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.089577</td>\n",
              "      <td>0.108501</td>\n",
              "      <td>0.910697</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.046465</td>\n",
              "      <td>0.078758</td>\n",
              "      <td>0.932287</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.029719</td>\n",
              "      <td>0.062852</td>\n",
              "      <td>0.946025</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.022896</td>\n",
              "      <td>0.053008</td>\n",
              "      <td>0.954367</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.019905</td>\n",
              "      <td>0.046501</td>\n",
              "      <td>0.962218</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.018413</td>\n",
              "      <td>0.041952</td>\n",
              "      <td>0.965162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.017528</td>\n",
              "      <td>0.038611</td>\n",
              "      <td>0.967125</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}